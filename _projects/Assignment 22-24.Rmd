---
title: "Exercise 22-24"
author: "Alex"
date: "29/10/2019"
output: html_document
---
## Chapter 22 Exercise 22.1
```{r}
# Question a
library("boot")
#using stepwise AIC selection
NucZero <- lm(cost~1,data=nuclear)
Nucstep <- step(NucZero,scope=.~.+date+t1+t2+cap+pr+ne+ct+bw+cum.n+pt,direction="both")
summary(Nucstep) #final model
# Question b 
#The final model in (a) is different from that selected by either forward or backward elimination. Although it is more similar to the model chosen through backward selection. It differs only by an additional, non-significant, effect for 'ct'.
# Question c
Galball <- data.frame(d=c(573,534,495,451,395,337,253),h=c(1,0.8,0.6,0.45,0.3,0.2,0.1))
Galmod0 <- lm(d~1,data=Galball)
Galmod1 <- lm(d~h,data=Galball)
Galmod2 <- lm(d~h+I(h^2),data=Galball)
Galmod3 <- lm(d~h+I(h^2)+I(h^3),data=Galball)
Galmod4 <- lm(d~h+I(h^2)+I(h^3)+I(h^4),data=Galball)
# Question d
anova(Galmod0,Galmod1,Galmod2,Galmod3,Galmod4)
# Yes, the model chosen via nested partial F-tests is consistent with the cubic model in Exercise 21.2 (b) and (c). 
# Question e
library("faraway")
DiabNew <- na.omit(diabetes[,c("chol","age","gender","height","weight","frame","waist","hip","location")])
DiabNew
# Question f
dia.null <- lm(chol~1,data=DiabNew)
dia.null
dia.full <- lm(chol~age*gender*weight*frame+waist*height*hip+location,data=DiabNew)
dia.full
# Question g
Diastep <- step(dia.null,scope=.~.+age*gender*weight*frame+waist*height*hip+location)
summary(Diastep)
# Question h
add1(dia.null,scope=.~.+age*gender*weight*frame+waist*height*hip+location,test="F")
add1
dia.1 <- update(dia.null,.~.+age)
dia.1
add1(dia.1,scope=.~.+age*gender*weight*frame+waist*height*hip+location,test="F")
dia.2 <- update(dia.1,.~.+frame)
add1(dia.2,scope=.~.+age*gender*weight*frame+waist*height*hip+location,test="F")
summary(dia.2)
# The two models in (g) and (h) are different. Step-wise AIC has chosen a model that includes the two-way interaction between 'age' and 'frame', as well as a main effect for 'waist'. Performing forward selection halts after main effects for 'age' and 'frame' are added only, with no further additions offering a statistically significant improvement to goodness-of-fit.
# i
dia.step2 <- step(dia.full)
summary(dia.step2)
# The model chosen via step-wise AIC when starting from 'dia.full' is far, far more complex than the AIC-selected model in (g). The model contains a three-way interaction between 'age', 'gender' and 'weight', and all lower-order effects, as well as main effects and a two-way interaction between 'waist' and 'hip'. By starting from the very complex model, it seems we've accessed potential candidate models which have AIC values that are lower than those accessible by starting the selection algorithm at the null (intercept-only) model. For this reason, the final model reached in this way refuses to move to the simpler model selected in (g) since it's already found a model with a lower value for that criterion. Whether or not we'd be willing to settle on this rather complex model for predictive purposes is a more difficult question to answer...
# Question j
library("MASS")
Carnull <- lm(I(1/mpg)~1,data=mtcars)
Carstep <- step(Carnull,scope=.~.+wt*hp*factor(cyl)*disp+am+factor(gear)+drat+vs+qsec+carb)
summary(Carstep)
# Modeling the response as GPM instead of MPG, step-wise AIC selection offers up a far simpler model, with main effects for 'wt' and 'hp' only. It would seem that this transformation of the response greatly simplifies the relationships in the data.

## Exercise 22.2 
# Question a
library("boot")
Nucfit <- lm(cost~date+cap+pt+ne,data=nuclear)
summary(Nucfit)
# Question b
plot(Nucfit,which=1)
plot(Nucfit,which=2)
# The residuals vs. fitted plot doesn't suggest any major causes of concern: the points appear randomly scattered around zero with no indication of heteroscedasticity. However, there is one clear extreme observation, labeled 19, that is an outlier. The QQ plot also shows little cause for concern with fairly modest deviation of the residuals from the normal quantiles, though again, observation 19 being an outlier departs considerably from the other distribution. It appears reasonable to assume satisfaction of the error assumptions for since there is no clear violation.
# Question c
cutoff <- 4/nrow(nuclear)
cutoff
plot(Nucfit,which=4)
abline(h=cutoff,lty=2)
# The Cook's distances shows that observation 19 is highly influential. It breaches the rule-of-thumb cut-off of 0.125 by a considerable amount. Observation 10 is the next most influential, however its Cook's distance is less than 0.125.
# Question d
comboplot<- plot(Nucfit,which=5,cook.levels=c(cutoff,0.5,1))
comboplot
# Observation 19 sits in a low-to-medium leverage position; it's the large residual for that point that pushes it past the rule-of-thumb contour. The same characterization can be applied to the other two labeled points that have more or less the same leverage (observations 10 and 12), though their smaller residuals mean a correspondingly lower influence.
# Question e
Nucfit2 <- lm(cost~date+cap+pt+ne,data=nuclear[-19,])
summary(Nucfit2)
plot(Nucfit2,which=1)
plot(Nucfit2,which=2)
# Assuming there's a good reason to remove observation 19, once done so, the plots of the residuals are improved in terms of satisfaction of the assumptions of the error component. Independence and homgeneity are illustrated with randomness around zero, and normality also appears reasonable. Points 10 and 12 are now the top two extreme points, joined by observation 7.
# Question f
library("faraway")
Diafit <- lm(chol~age*frame+waist,data=diabetes)
summary(Diafit)
# Question g
plot(Diafit,which=1)
plot(Diafit,which=2)
# Very similar to the interpretation of the plots in the earlier exercise (b), the error assumptions seem satisfied here, with randomness around zero and homoscedasticity seemingly valid. There are some extreme positive residuals, namely point 63. The QQ plot does appear to exhibit some departure from normality in the upper tail, with the three extreme points 63, 295 and 148 not helping in that respect. Estimation will remain valid if normality is questionable, though the estmates might not be 'optimal' in a theoretical sense.
# Question h
nrow(diabetes)-15
cutoff <- 4/(nrow(diabetes)-15)
cutoff
plot(Diafit,which=5,cook.levels=c(1,3,5)*cutoff)
# The size of the data set results in a relatively small rule-of-thumb influence cut-off of around 0.01. A number of points breach this mark, though the overall pattern of the standardized residuals vs. leverage appears consistent with the contours, so we shouldn't be especially concerned here. There are three points that breach the '3 times cut-off' contour. Point 63 is in a very low leverage position, but its extreme residual leads it to be highly influential. Points 4 and 148 have much smaller residuals, but their position in much higher leverage areas when compared with 63 which means they too are considered highly influential here.
# Question i
dia.url <- "http://www.jse.amstat.org/v9n2/4Cdata.txt"
diamonds <- read.table(url(dia.url))
names(diamonds) <- c("Carat","Color","Clarity","Cert","Price")
plot(diamonds$Carat,diamonds$Price,pch=19,col=as.numeric(diamonds$Clarity))
legend("topleft",legend=levels(diamonds$Clarity),col=1:length(levels(diamonds$Clarity)),pch=19)
plot(diamonds$Carat,diamonds$Price,pch=19,col=as.numeric(diamonds$Color))
legend("topleft",legend=levels(diamonds$Color),col=1:length(levels(diamonds$Color)),pch=19)
plot(diamonds$Carat,diamonds$Price,pch=19,col=as.numeric(diamonds$Cert))
legend("topleft",legend=levels(diamonds$Cert),col=1:length(levels(diamonds$Cert)),pch=19)
# Question j
sparkly.fit <- lm(Price~Carat+Color+Clarity+Cert,data=diamonds)
summary(sparkly.fit)
plot(sparkly.fit,which=1)
plot(sparkly.fit,which=2)
plot(sparkly.fit,which=3)
# There seems to be clear, systematic non-linearity in the estimated residuals. This violates the linearity assumption of the trends in our data, and suggests our current model is inadequate in terms of representation of the data at hand. Based on the plots from (i), should we try modeling a log-transformation of the response?
# Normality is also affected---there is rather obvious deviation, from the distribution, particularly in the upper tail.
# Barring three extreme points, though, plots 1 and 3 don't show that the assumptions of homoscedasticity is violated---the variability of the residuals remains more or less constant.
# Question k
sparkly.fit2 <- lm(log(Price)~Carat+Color+Clarity+Cert,data=diamonds)
summary(sparkly.fit2)
plot(sparkly.fit2,which=1)
plot(sparkly.fit2,which=2)
plot(sparkly.fit2,which=3)
# Log-transformation of Price has done nothing to curb the clear, systematic, non-linear appearance of the residuals. A non-linear trend still appears very promenent.
# However, the log-transformation has reigned in the extreme points and the severity of the non-normality to a certain extent.
# Question l
sparkly.fit3 <- lm(log(Price)~Carat+I(Carat^2)+Color+Clarity+Cert,data=diamonds)
summary(sparkly.fit3)
plot(sparkly.fit3,which=1)
plot(sparkly.fit3,which=2)
plot(sparkly.fit3,which=3)
# Including an order 2 polynomial term in Carat has eliminated much of the concern of the non-linear curvature.
# Normality is more apparent now, and there's little if any concern of heteroscedasticity.
# This third model is by far the most appropriate of the three (with respect to the residual diagnostics) when it comes to modeling the cost of diamonds in light of the available data.
```

## Chapter 23 Exercise 23.1 
```{r}
# Question a
par(mfrow=c(2,1))
boxplot(mtcars$mpg~mtcars$cyl,xlab="Cylinders",ylab="MPG")
carfit <- lm(mpg~cyl,data=mtcars)
plot(mtcars$mpg~mtcars$cyl,xlab="Cylinders",ylab="MPG")
abline(carfit,lwd=2)
# Question b
# i
laymat <- cbind(c(2,1,1,3),c(2,1,1,3))
laymat
layout(laymat)
layout.show(3)
# ii
laymat <- rbind(c(1,1,2,3),c(1,1,4,5))
laymat
layout(laymat)
layout.show(5)
# iii
laymat <- cbind(c(2,3,3,1),c(2,3,3,1),c(2,4,5,1))
laymat
layout(laymat)
layout.show(5)
# Question c
dev.new(width=9,height=4.5)
laymat <- rbind(c(1,1,2,4),c(1,1,3,4))
layout(laymat)
layout.show(4)
par(mar=c(4,4,2,1))
plot(quakes$long,quakes$lat,cex=0.02*quakes$stations,xlab="Longitude",ylab="Latitude")
box(which="figure",col="gray")
plot(quakes$mag,quakes$stations,xlab="Magnitude",ylab="Stations")
box(which="figure",col="gray")
plot(quakes$depth,quakes$stations,xlab="Depth",ylab="Stations")
box(which="figure",col="gray")
hist(quakes$stations,main="",xlab="Stations")
abline(v=mean(quakes$stations),lty=2)
box(which="figure",col="gray")
# Question d
interactive.arrow <- function(...,label=NA){
    arr.pts <- locator(2)
    arrows(x0=arr.pts$x[1],y0=arr.pts$y[1],x1=arr.pts$x[2],y1=arr.pts$y[2],...)
    if(!is.na(label)){
      lab.pt <- text(locator(1),label=label,xpd=NA)
     
    }
}
boxplot(quakes$mag)
interactive.arrow(xpd=TRUE,label="minumum")
interactive.arrow(xpd=TRUE,label="1st quartile")
interactive.arrow(xpd=TRUE,label="median")
interactive.arrow(xpd=TRUE,label="3rd quartile")
interactive.arrow(xpd=TRUE,label="maximum")
interactive.arrow(xpd=TRUE,label="outliers")

## Exercise 23.2 
Diaurl <- "http://jse.amstat.org/v9n2/4Cdata.txt"
diamonds <- read.table(Diaurl)
names(diamonds) <- c("Carat","Color","Clarity","Cert","Price")
# Question a
dev.new(width=6,height=6)
par(mar=c(0,4,2,0))
# i
boxplot(diamonds$Price~diamonds$Cert,axes=FALSE,frame=FALSE,main="Diamond Prices by Certification")
# ii
axis(2,at=seq(0,18000,2000),las=1,tcl=1,mgp=c(3,0.5,0))
# iii
text(locator(1),"SGD$",xpd=TRUE)
text(locator(1),"GIA",cex=1.5)
text(locator(1),"HRD",cex=1.5)
text(locator(1),"IGI",cex=1.5)
# Question b
dev.new(width=8,height=7)
par(mar=c(2,5,3,5),oma=c(2,rep(1,3)))
# i
plot(diamonds$Price~diamonds$Carat,col=c("red","green","blue")[as.numeric(diamonds$Cert)],axes=FALSE,ann=FALSE)
box(bty="u")
# ii
axis(1,at=seq(0.2,1.1,0.1),font=4,mgp=c(3,0.5,0))
axis(1,at=seq(0.15,1.05,0.1),tcl=-0.25,labels=FALSE)
# iii
axis(2,at=seq(1000,17000,2000),las=1,font=4)
axis(4,at=seq(1000,11000,1000)*1.37,labels=seq(1000,11000,1000),las=1,font=4)
# iv
dia.fit <- lm(Price~Carat+I(Carat^2),data=diamonds)
carat.seq <- seq(min(diamonds$Carat),max(diamonds$Carat),length=100)
dia.pred <- predict(dia.fit,newdata=data.frame(Carat=carat.seq),interval="prediction")
lines(carat.seq,dia.pred[,1],col="gray",lwd=2)
lines(carat.seq,dia.pred[,2],col="gray",lty=2)
lines(carat.seq,dia.pred[,3],col="gray",lty=2)
# v
expr1 <- expression("USD$"%~~%1.37%*%"SGD$")
expr2 <- expression(paste("Price"==beta[0]+beta[1],"Carat",+beta[2],"Carat"^2))
# vi
mtext("CARAT",side=1,line=0,outer=TRUE)
mtext("SGD$",side=2,line=4)
mtext("Scatterplot of Diamond Price by Carat and Certification",side=3,line=2,cex=1.5)
mtext(expr1,side=4,line=4)
# vii
interactive.arrow(label=expr2)
# viii
legend(locator(1),legend=levels(diamonds$Cert),col=c("red","green","blue"),pch=1)
```
## Chapter 24 Exercise 24.1
```{r}
library("MASS")
?UScereal
library("ggplot2")
# Question a
cereal <- UScereal
new.mfr <- as.numeric(UScereal$mfr)
new.mfr[new.mfr>2] <- 3
cereal$mfr <- factor(new.mfr,labels=c("General Mills","Kelloggs","Other"))
cereal$shelf <- factor(cereal$shelf)
# Question b
# i
gg1 <- ggplot(cereal,aes(x=protein,y=calories,col=shelf)) + geom_point(aes(shape=mfr)) + geom_smooth(method="lm") + labs(x="Protein",y="Calories",col="Shelf",size="Carbs",shape="Manufacturer")
gg1
# ii
gg2 <- ggplot(cereal,aes(x=calories,fill=shelf)) + geom_density(alpha=0.5) + labs(x="Calories",y="Kernel estimate",fill="Shelf")
gg2
# Question c
library("gridExtra")
grid.arrange(gg1,gg2)
# Question d
ggplot(cereal,aes(x=protein,y=calories)) + geom_point(aes(col=sugars,size=sodium,shape=shelf)) + geom_smooth(method="loess",span=0.9) + facet_wrap(~mfr) + labs(x="Protein",y="Calories",col="Sugars",shape="Shelf",size="Sodium")
# Question e
library("car")
gg1 <- ggplot(Salaries,aes(x=yrs.service,y=salary,col=sex)) + geom_point() + geom_smooth(method="loess") + labs(x="Years of Service",y="Salary",col="Sex")
gg1
# Question f
# i
gg2 <- ggplot(Salaries,aes(x=rank,y=salary,col=sex)) + geom_boxplot() + labs(x="Rank",y="Salary",col="Sex")
gg2
# ii
gg3 <- ggplot(Salaries,aes(x=discipline,y=salary,fill=sex)) + geom_boxplot() + labs(x="Discipline",y="Salary",fill="Sex")
gg3
# iii
gg4 <- ggplot(Salaries,aes(x=salary,fill=rank)) + geom_density(alpha=0.3) + labs(x="Salary",y="Kernel estimate",fill="Rank")
gg4
# Question g
grid.arrange(gg1,gg2,gg3,gg4)
# Question h
# i
ggplot(Salaries,aes(x=salary,fill=sex)) + geom_density(alpha=0.7) + facet_wrap(~rank) + labs(x="Salary",y="Kernel estimate",fill="Sex")
# ii
ggplot(Salaries,aes(x=yrs.service,y=salary,col=sex)) + geom_point() + geom_smooth(method="lm") + facet_grid(discipline~rank,scales="free_x") + labs(x="Years of Service",y="Salary",col="Sex")

## Exercise 24.2 
library("ggvis")
library("car")
?Salaries
# Question a
salfill <- input_radiobuttons(c("Rank"="rank","Discipline"="discipline","Sex"="sex"),map=as.name,label="Color points by...")
Salaries %>% ggvis(x=~yrs.service,y=~salary,fill=salfill) %>% layer_points() %>% add_legend("fill",title="") %>% add_axis("x",title="Years of service") %>% add_axis("y",title="Salary")
# Question b
# i
Salaries %>% ggvis(x=~salary,fill=~rank) %>% group_by(rank) %>% layer_densities()
# ii
Salaries %>% ggvis(x=~salary,fill=~rank) %>% group_by(rank) %>% layer_densities(adjust=input_slider(0.1,2,label="Smoothness")) %>% add_axis("x",title="Salary") %>% add_axis("y",title="Kernel estimate") %>% add_legend("fill",title="Rank")
# Question c
library("MASS")
cereal <- UScereal
new.mfr <- as.numeric(UScereal$mfr)
new.mfr[new.mfr>2] <- 3
cereal$mfr <- factor(new.mfr,labels=c("General Mills","Kelloggs","Other"))
cereal$shelf <- factor(cereal$shelf)
filler <- input_radiobuttons(c("Manufacturer"="mfr","Shelf"="shelf","Vitamins"="vitamins"),map=as.name,label="Color points by...")
sizer <- input_slider(10,300,label="Point size:")
opacityer <- input_slider(0.1,1,label="Opacity:")
# Question d
cereal %>% ggvis(x=~protein,y=~calories,fill=filler,size:=sizer,opacity:=opacityer) %>% layer_points() %>% add_axis("x",title="Protein") %>% add_axis("y",title="Calories") %>% add_legend("fill",title="")
# Question e
shaper <- input_radiobuttons(c("Manufacturer"="mfr","Shelf"="shelf","Vitamins"="vitamins"),map=as.name,label="Shape points by...")
# Question f
cereal %>% ggvis(x=~protein,y=~calories,fill=filler,shape=shaper,opacity:=opacityer,size:=sizer) %>% layer_points() %>% add_axis("x",title="Protein") %>% add_axis("y",title="Calories") %>% add_legend("fill",title="") %>% add_legend("shape",title="",properties=legend_props(legend=list(y=100))) %>% set_options(duration=0)

```

